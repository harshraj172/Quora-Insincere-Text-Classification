{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quora Insicere Text Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIEPxom99iLJ"
      },
      "source": [
        "mkdir .kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL8UdSY79oLn"
      },
      "source": [
        "import json\r\n",
        "token = {\r\n",
        "  \"username\": \"harsh777111raj\",\r\n",
        "  \"key\": \"532bd9a20e4c1f82428b14be4d34a5ff\"\r\n",
        "}\r\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\r\n",
        "    json.dump(token, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uR3D-qv92Tu"
      },
      "source": [
        "!mv .kaggle /root/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H59W1tT9tPK",
        "outputId": "2460e352-46c7-4667-b371-2555ef9af8b1"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/.kaggle/kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oghnSVGG9woj",
        "outputId": "8611b3d2-6ebf-44fd-a7dc-aeed7391e6b2"
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3KH7vvR9-5-"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBYnu85A-CAu",
        "outputId": "07a7e581-a40d-4e5b-ab25-d20e276ff7de"
      },
      "source": [
        "!kaggle competitions download -c quora-insincere-questions-classification -p /content "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 93% 51.0M/54.9M [00:01<00:00, 31.0MB/s]\n",
            "100% 54.9M/54.9M [00:01<00:00, 51.5MB/s]\n",
            "Downloading embeddings.zip to /content\n",
            "100% 5.94G/5.96G [01:27<00:00, 123MB/s]\n",
            "100% 5.96G/5.96G [01:27<00:00, 72.9MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "100% 4.09M/4.09M [00:00<00:00, 19.0MB/s]\n",
            "\n",
            "Downloading test.csv.zip to /content\n",
            "100% 15.8M/15.8M [00:00<00:00, 29.8MB/s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR_nzHCX-mK2",
        "outputId": "144b095e-c140-4206-acba-1ddd19158f91"
      },
      "source": [
        "!kaggle datasets download -d iezepov/gensim-embeddings-dataset -p /content "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading gensim-embeddings-dataset.zip to /content\n",
            "100% 8.47G/8.47G [02:26<00:00, 70.1MB/s]\n",
            "100% 8.47G/8.47G [02:26<00:00, 62.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb1vqo7C_O2G",
        "outputId": "85943761-750b-4ac0-9e18-5478deea08f6"
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "\n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n",
            "\n",
            "Archive:  gensim-embeddings-dataset.zip\n",
            "  inflating: GoogleNews-vectors-negative300.gensim  \n",
            "  inflating: GoogleNews-vectors-negative300.gensim.vectors.npy  \n",
            "  inflating: crawl-300d-2M.gensim    \n",
            "  inflating: crawl-300d-2M.gensim.vectors.npy  \n",
            "  inflating: glove.840B.300d.gensim  \n",
            "  inflating: glove.840B.300d.gensim.vectors.npy  \n",
            "  inflating: glove.twitter.27B.200d.gensim  \n",
            "  inflating: glove.twitter.27B.200d.gensim.vectors.npy  \n",
            "  inflating: numberbatch-en.gensim   \n",
            "  inflating: numberbatch-en.gensim.vectors.npy  \n",
            "  inflating: paragram_300_sl999.gensim  \n",
            "  inflating: paragram_300_sl999.gensim.vectors.npy  \n",
            "\n",
            "Archive:  embeddings.zip\n",
            "   creating: GoogleNews-vectors-negative300/\n",
            "   creating: glove.840B.300d/\n",
            "   creating: paragram_300_sl999/\n",
            "   creating: wiki-news-300d-1M/\n",
            "  inflating: glove.840B.300d/glove.840B.300d.txt  \n",
            "  inflating: GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin  \n",
            "  inflating: wiki-news-300d-1M/wiki-news-300d-1M.vec  \n",
            "  inflating: paragram_300_sl999/README.txt  \n",
            "  inflating: paragram_300_sl999/paragram_300_sl999.txt  \n",
            "\n",
            "5 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itKAIvf3-rvJ",
        "outputId": "7b28cf9b-69b5-426e-feb8-89ec170331b2"
      },
      "source": [
        "!unzip /content/test.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/test.csv.zip\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pB8rabI_KvK",
        "outputId": "ef881939-0447-4e0f-feac-3549b1492d9c"
      },
      "source": [
        " !unzip /content/train.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/train.csv.zip\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gt0rWYv_sF_"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "from keras.models import Sequential\r\n",
        "import keras.utils as ku \r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np \r\n",
        "import string, os \r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6Ej63A_sC9"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/train.csv\")\r\n",
        "test_df = pd.read_csv(\"/content/test.csv\")\r\n",
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikNtZ9Ej_sAG"
      },
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "\r\n",
        "def preprocessing(sentences):\r\n",
        "  transformed = []\r\n",
        "  lemmatizer = WordNetLemmatizer()\r\n",
        "  puncts = [',','.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \r\n",
        "          \"'\",  '&', '/', '[', ']', '>', '<', '%', '=', '#', '+', \r\n",
        "          '\\\\',  '§', '″', '′','¿','═','0','1','2','3','4','5','6','7','8','9','_','@','*','`']\r\n",
        "  for sentence in sentences:\r\n",
        "    sentence = str(sentence).lower()\r\n",
        "    for punct in puncts:\r\n",
        "      sentence = str(sentence).replace(punct, \"\")\r\n",
        "    sentence = remove_stopwords(sentence)\r\n",
        "    sentence = lemmatizer.lemmatize(sentence)\r\n",
        "    transformed.append(sentence)\r\n",
        "  return transformed\r\n",
        "\r\n",
        "train_df.text = preprocessing(train_df.text)\r\n",
        "train_df.selected_text = preprocessing(train_df.selected_text)\r\n",
        "test_df.text = preprocessing(test_df.text)\r\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQLyWpvB_r7W"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "max_features = 95000\r\n",
        "\r\n",
        "tokenizer = Tokenizer(num_words = max_features, filters='')\r\n",
        "tokenizer.fit_on_texts(list(train_df.question_text)+list(test_df.question_text))\r\n",
        "\r\n",
        "X_train = tokenizer.texts_to_sequences(list(train_df.question_text))\r\n",
        "X_test = tokenizer.texts_to_sequences(list(test_df.question_text))\r\n",
        "\r\n",
        "vocabulary = tokenizer.word_index\r\n",
        "\r\n",
        "y_train = train_df.target\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNZHcJxI_rvO"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "MAXLEN = 70\r\n",
        "X_train = pad_sequences(X_train, maxlen = MAXLEN, padding='pre')\r\n",
        "X_test = pad_sequences(X_train, maxlen = MAXLEN, padding='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LINkzV4X_4J1"
      },
      "source": [
        "from gensim.models import KeyedVectors\r\n",
        "\r\n",
        "embedding_glove = KeyedVectors.load(f\"/content/glove.840B.300d.gensim\")\r\n",
        "embedding glove = KeyedVectors.load(f\"GoogleNews-vectors-negative300/\")\r\n",
        "embedding_paragram = KeyedVectors.load(f\"/content/paragram_300_sl999.gensim\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NUbN6SQTABC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9640753a-f2a6-41c1-913b-5464363c5f10"
      },
      "source": [
        "def check_coverage(vocab, embedding_index, embedding_name):\r\n",
        "    in_vocab = {}\r\n",
        "    out_of_vocab = {}\r\n",
        "    for word in vocab:\r\n",
        "        try:\r\n",
        "            in_vocab[word] = embedding_index[word]\r\n",
        "        except:\r\n",
        "            out_of_vocab[word] = vocab[word]\r\n",
        "            \r\n",
        "    print(f\"{len(in_vocab)/len(vocab):.0%}\"\r\n",
        "         f\"{embedding_name}\")\r\n",
        "\r\n",
        "check_coverage(vocabulary, embedding_glove, \"glove\")\r\n",
        "check_coverage(vocabulary, embedding_google, \"google\")\r\n",
        "check_coverage(vocabulary, embedding_paragram, \"paragram\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56%glove\n",
            "67%paragram\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lZI16r0_6q2"
      },
      "source": [
        "def get_embedding_matrix(vocab, embedding_index):\r\n",
        "    \r\n",
        "    embedding_matrix = np.zeros((len(vocab) + 1, 300))\r\n",
        "\r\n",
        "    for word, i in vocab.items(): \r\n",
        "        if word in embedding_index:\r\n",
        "            embedding_matrix[i] = embedding_index[word]\r\n",
        "\r\n",
        "    return embedding_matrix\r\n",
        "\r\n",
        "embedding_matrix_glove = get_embedding_matrix(vocabulary, embedding_glove)\r\n",
        "embedding_matrix_paragram = get_embedding_matrix(vocabulary, embedding_paragram)\r\n",
        "\r\n",
        "embedding_matrix = np.mean([1.4 * embedding_matrix_glove, \r\n",
        "                             0.6 * embedding_matrix_paragram], \r\n",
        "                           axis = 0)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4T94VAe_4G9"
      },
      "source": [
        "embed_size = embedding_matrix.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Aurx6-sTPAk"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "model = tf.keras.Sequential()\r\n",
        "model.add(tf.keras.layers.Embedding(max_features, embed_size))\r\n",
        "model.add(tf.keras.layers.Bidirectional(LSTM(embed_size, return_sequences = True)))\r\n",
        "model.add(tf.keras.layers.SpatialDropout1D(0.2))\r\n",
        "model.add(tf.keras.layers.Conv1D(128, 5))\r\n",
        "model.add(tf.keras.layers.GlobalMaxPool1D(data_format='channels_last'))\r\n",
        "model.add(tf.keras.layers.Dense(1, activation='softmax'))\r\n",
        "\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\r\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQPk_aLAABH1"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=1, verbose=2)\r\n",
        "y_predicted = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}